{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/aderaustmit/air_hockey_challenge/blob/warm-up/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "oBfdVdpCNKxg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(\"test\")\n",
    "\n",
    "import torch\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Network(nn.Module):\n",
    "    def __init__(self, input_shape, output_shape, n_features, **kwargs):\n",
    "        super(Network, self).__init__()\n",
    "\n",
    "        self._h1 = nn.Linear(input_shape[0], n_features)\n",
    "        self._h2 = nn.Linear(n_features, n_features)\n",
    "        self._h3 = nn.Linear(n_features, output_shape[0])\n",
    "\n",
    "        nn.init.xavier_uniform_(self._h1.weight,\n",
    "                                gain=nn.init.calculate_gain('tanh'))\n",
    "        nn.init.xavier_uniform_(self._h2.weight,\n",
    "                                gain=nn.init.calculate_gain('tanh'))\n",
    "        nn.init.xavier_uniform_(self._h3.weight,\n",
    "                                gain=nn.init.calculate_gain('linear'))\n",
    "\n",
    "    def forward(self, obs, **kwargs):\n",
    "        features1 = torch.tanh(self._h1(torch.squeeze(obs, 1).float()))\n",
    "        features2 = torch.tanh(self._h2(features1))\n",
    "        return self._h3(features2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from air_hockey_challenge.framework.evaluate_agent import PENALTY_POINTS\n",
    "from air_hockey_challenge.utils.kinematics import forward_kinematics\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def custom_reward_function(base_env, state, action, next_state, absorbing):\n",
    "    reward = -0.1 # small value to disincentivate long runs: faster is better\n",
    "\n",
    "    q = state[base_env.env_info['joint_pos_ids']]\n",
    "    dq = state[base_env.env_info['joint_vel_ids']]\n",
    "\n",
    "    # Get a dictionary of the constraint functions {\"constraint_name\": ndarray}\n",
    "    c = base_env.env_info['constraints'].fun(q, dq)\n",
    "\n",
    "    # for k,v in c.items():\n",
    "    #     reward -= PENALTY_POINTS[k] * np.sum(v > 0)\n",
    "    # mybe not ideal: penalty is flat outside, does not know how to improve --> use violation instead of points?\n",
    "\n",
    "    for k,val in c.items():\n",
    "        for v in val:\n",
    "            reward -= v if v > 0 else 0\n",
    "\n",
    "    # TODO reward for good actions --> score\n",
    "    # for now --> try to go to the puck\n",
    "    \n",
    "    ee_pos = forward_kinematics(base_env.env_info['robot']['robot_model'], base_env.env_info['robot']['robot_data'], q)[0]\n",
    "    puck_pos = base_env.env_info['puck_pos_ids']\n",
    "    puck_vel = np.linalg.norm(state[base_env.env_info['puck_vel_ids']])\n",
    "    reward += -np.linalg.norm(ee_pos - puck_pos) if puck_vel < 0.1 else puck_vel\n",
    "\n",
    "    return reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mushroom_rl.algorithms.actor_critic import PPO\n",
    "\n",
    "class PPOAgent(PPO): # Just to fix the action shape\n",
    "    def draw_action(self, state):\n",
    "        return super().draw_action(state).reshape(2,3)\n",
    "    \n",
    "    def fit(self, dataset, **info):\n",
    "        for i in range(len(dataset)):\n",
    "            dataset[i] = list(dataset[i])\n",
    "            dataset[i][1] = dataset[i][1].flatten()\n",
    "        return super().fit(dataset, **info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from air_hockey_challenge.framework.air_hockey_challenge_wrapper import AirHockeyChallengeWrapper\n",
    "from air_hockey_challenge.framework.challenge_core import ChallengeCore\n",
    "\n",
    "\n",
    "from mushroom_rl.core import Logger\n",
    "from mushroom_rl.algorithms.actor_critic import PPO\n",
    "from mushroom_rl.policy import GaussianTorchPolicy\n",
    "\n",
    "from mushroom_rl.utils.dataset import compute_metrics\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "cuda = torch.cuda.is_available()\n",
    "\n",
    "# logger = Logger(PPO.__name__, results_dir=None)\n",
    "# logger.strong_line()\n",
    "# logger.info('Experiment Algorithm: ' + PPO.__name__)\n",
    "\n",
    "mdp = AirHockeyChallengeWrapper(\"3dof-hit\", custom_reward_function=custom_reward_function)\n",
    "mdp.reset()\n",
    "\n",
    "critic_params = dict(network=Network,\n",
    "                        optimizer={'class': torch.optim.Adam,\n",
    "                                'params': {}},\n",
    "                        loss=torch.nn.functional.mse_loss,\n",
    "                        n_features=64,\n",
    "                        batch_size=64,\n",
    "                        input_shape=(12,),\n",
    "                        output_shape=(1,), \n",
    "                        use_cuda = cuda)\n",
    "\n",
    "alg_params = dict(actor_optimizer={'class': torch.optim.Adam,\n",
    "                                    'params': {}},\n",
    "                    critic_params=critic_params,\n",
    "                    n_epochs_policy = 1,\n",
    "                    batch_size = 5,\n",
    "                    eps_ppo = 0.01,\n",
    "                    lam = 0.95,\n",
    "                 )\n",
    "\n",
    "policy_params = dict(\n",
    "    std_0=1.,\n",
    "    n_features=64,\n",
    "    use_cuda=cuda\n",
    ")\n",
    "\n",
    "policy = GaussianTorchPolicy(Network,\n",
    "                                (12,),\n",
    "                                (6,),\n",
    "                                **policy_params)\n",
    "# policy.load(\"dataset/policy\")\n",
    "\n",
    "agent = PPOAgent(mdp.info, policy, **alg_params)\n",
    "\n",
    "# Algorithm\n",
    "core = ChallengeCore(agent, mdp)\n",
    "\n",
    "def train(n_epochs, n_episode_learn, n_episode_eval, n_episode_per_fit):\n",
    "    dataset = core.evaluate(n_episodes=n_episode_eval, render=False)\n",
    "    metrics = compute_metrics(dataset)\n",
    "    # logger.epoch_info(0, metrics=metrics)\n",
    "    # logger.info('Tranining start')\n",
    "    print(\"Epoch:\",0,\"metrics:\",metrics)\n",
    "    print(\"Training start\")\n",
    "    \n",
    "    for n in tqdm(range(n_epochs)):\n",
    "        core.learn(n_episodes=n_episode_learn, n_episodes_per_fit=n_episode_per_fit)\n",
    "        dataset = core.evaluate(n_episodes=n_episode_eval, render=False)\n",
    "        metrics = compute_metrics(dataset)\n",
    "        # logger.epoch_info(n+1, metrics=metrics)\n",
    "        print(\"Epoch:\",n+1,\"metrics:\",metrics)\n",
    "        agent.save(f\"dataset/PPO2/epoch_{n+1}.pkl\")\n",
    "\n",
    "    # logger.info('Tranining end')\n",
    "    print(\"Training end\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 metrics: (-4992.14380677302, -267.5048820310003, -1989.3761599160575, -1757.0554467926258, 10)\n",
      "Training start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [54:52<8:13:52, 3292.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 metrics: (-4751.868966880249, -2335.0301214699375, -3485.3302996413404, -3572.6082714262766, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [1:48:17<7:12:06, 3240.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 metrics: (-3660.4370470741437, 358.6663545132245, -1780.0691811621787, -2122.2385564724887, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [2:45:34<6:28:33, 3330.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 metrics: (-1735.5040761933822, 281.13644188749765, -995.5624805656504, -1047.5318301626112, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [3:42:11<5:35:41, 3356.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 metrics: (-2831.1859387271593, -1116.6242746480095, -2147.188542408853, -2322.363855299334, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [4:44:46<4:51:41, 3500.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 metrics: (-2528.0538587838405, -210.33383775199354, -1448.4856291174278, -1455.9069276596522, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [5:41:22<3:50:58, 3464.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 metrics: (-1853.1781504038697, -211.4482764859941, -1276.6910332846758, -1452.3667607820053, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [6:37:36<2:51:45, 3435.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 metrics: (-2106.673601343533, 99.78590338233307, -1128.1778793773851, -1163.270868535404, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [7:31:53<1:52:36, 3378.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 metrics: (-1743.8528023399085, 108.41786767452669, -950.538223178788, -874.4067718341444, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [8:28:22<56:21, 3381.94s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 metrics: (-2486.18798590034, -480.1391371448809, -1617.652262087477, -1744.2412107883458, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [9:26:26<00:00, 3398.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 metrics: (-1675.5107914164626, 668.7345111020212, -771.8362605178797, -803.2625099056299, 10)\n",
      "Training end\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train(n_epochs=10, n_episode_learn=1000, n_episode_eval=10, n_episode_per_fit=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                             \r"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "dataset = core.evaluate(n_episodes=5, render=True)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNrmP6hXOIoS2cW74xktEOX",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
